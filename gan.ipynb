{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required modules.\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import (\n",
    "    generator,\n",
    "    discriminator,\n",
    "    iprint,\n",
    "    get_dataset,\n",
    "    load_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset and setting parameters.\n",
    "num_epochs = 1001\n",
    "lr = 0.001\n",
    "\n",
    "log_rate = 1\n",
    "\n",
    "num_features = 64\n",
    "img_height, img_width, img_channels = (64, 64, 1)\n",
    "\n",
    "get_dataset('https://ipkill.org/1uFik', 'mnist.zip')\n",
    "dataset = load_dataset('mnist', resize_img=(img_height, img_width))\n",
    "\n",
    "datay = np.concatenate((dataset['train'][0], dataset['valid'][0], dataset['test'][0]))\n",
    "datay = datay.reshape((-1, img_height, img_width, img_channels))/255.\n",
    "\n",
    "datax = np.random.normal(size=(len(datay), num_features))\n",
    "\n",
    "iprint(datax.shape, datay.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the graph.\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x = tf.placeholder(tf.float32, (None, num_features))\n",
    "    y = tf.placeholder(tf.float32, (None, img_height, img_width, img_channels))\n",
    "    \n",
    "    dp_rate = tf.placeholder(tf.float32)\n",
    "    \n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "    learning_rate = tf.placeholder(tf.float32)\n",
    "    \n",
    "    norm = tf.layers.batch_normalization(x, training=is_training)\n",
    "    \n",
    "    gimgs = generator(norm, dp_rate, is_training)\n",
    "    \n",
    "    dtlabels = discriminator(y, dp_rate, is_training)\n",
    "    dflabels = discriminator(gimgs, dp_rate, is_training, reuse=True)\n",
    "    \n",
    "    tloss = tf.losses.log_loss(tf.ones_like(dtlabels), dtlabels)\n",
    "    floss = tf.losses.log_loss(tf.zeros_like(dflabels), dflabels)\n",
    "    \n",
    "    gloss = tf.reduce_mean(tf.losses.log_loss(tf.ones_like(dflabels), dflabels))\n",
    "    dloss = tf.reduce_mean(0.5 * (tloss + floss))\n",
    "    \n",
    "    gvars = [v for v in tf.global_variables() if v.name.startswith('GEN')]\n",
    "    dvars = [v for v in tf.global_variables() if v.name.startswith('DIS')]\n",
    "    \n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        gtrain_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(gloss, var_list=gvars)\n",
    "        dtrain_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(dloss, var_list=dvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the tensorboard summarizer.\n",
    "tf_writer = tf.summary.FileWriter('logs', graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the train flow.\n",
    "def train(sess, ix, iy, lr, epoch, bs=32):\n",
    "    \n",
    "    assert len(ix) == len(iy)\n",
    "    \n",
    "    batch = np.random.permutation(len(ix))\n",
    "    \n",
    "    _gloss, _dloss = 0.0, 0.0\n",
    "    gtimes, dtimes = 0, 0\n",
    "    \n",
    "    start = time.time()\n",
    "    for i in range(0, len(ix), bs):\n",
    "        bx = ix.take(batch[i:i + bs], axis=0)\n",
    "        by = iy.take(batch[i:i + bs], axis=0)\n",
    "        \n",
    "        eval_dict = {\n",
    "            x: bx,\n",
    "            y: by,\n",
    "            dp_rate: 0.4,\n",
    "            is_training: False\n",
    "        }\n",
    "        \n",
    "        train_dict = {\n",
    "            x: bx,\n",
    "            y: by,\n",
    "            dp_rate: 0.4,\n",
    "            is_training: True,\n",
    "            learning_rate: lr,\n",
    "        }\n",
    "        \n",
    "        gls, dls = sess.run([gloss, dloss], feed_dict=eval_dict)\n",
    "        \n",
    "        train_g = gls * 1.5 >= dls\n",
    "        train_d = dls * 2 >= gls\n",
    "        \n",
    "        if train_d:\n",
    "            ret = sess.run([dtrain_op, dloss], feed_dict=train_dict)\n",
    "            _dloss += ret[1] * len(bx)\n",
    "            dtimes += len(bx)\n",
    "\n",
    "        if train_g:\n",
    "            ret = sess.run([gtrain_op, gloss], feed_dict=train_dict)\n",
    "            _gloss += ret[1] * len(bx)\n",
    "            gtimes += len(bx)\n",
    "\n",
    "        if i == 0:\n",
    "            tfwriter.add_summary(sess.run(summary, feed_dict=eval_dict), epoch)\n",
    "\n",
    "    if gtimes != 0:\n",
    "        _gloss /= gtimes\n",
    "    if dtimes != 0:\n",
    "        _dloss /= dtimes\n",
    "\n",
    "    if epoch % log_rate == 0:\n",
    "        print(\n",
    "            'epoch: %05d' % epoch,\n",
    "            'gloss: %07.3f' % _gloss,\n",
    "            'dloss: %07.3f' % _dloss,\n",
    "            'time: %07.3f' % (time.time() - start)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the session, (restoring,) training and saving the model.\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    tf_saver = tf.train.Saver(tf.trainable_variables(), max_to_keep=None)\n",
    "    \n",
    "#     tf_saver.restore(sess, os.path.join('models', 'gan.ckpt'))\n",
    "    \n",
    "    iprint('inicializando vari√°veis...', end=' ')\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Done')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train(sess, datax, datay, lr, epoch)\n",
    "    \n",
    "    tf_saver.save(sess, os.path.join('models', 'gan.ckpt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
